{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lib\n",
    "from IPython.display import Latex\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchsummary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Function\n",
    "import  visdom\n",
    "import scipy.sparse as sp\n",
    "import gurobipy as gp\n",
    "import itertools\n",
    "import pdb\n",
    "import datetime\n",
    "from random import choice\n",
    "from gurobipy import GRB\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir='2_layer_weights/32/'):\n",
    "    dict_param = {}\n",
    "    dict_param['w0'] = np.sign(np.load(data_dir+\"w0.npy\")).T\n",
    "    _, dict_param['size_input'] = np.shape(dict_param['w0'])\n",
    "    # we assume all hidden layers have the same number of neurons\n",
    "    dict_param['w1'] = np.sign(np.load(data_dir+\"w1.npy\")).T  \n",
    "    dict_param['size_hidden'] = np.shape(dict_param['w1'].T)\n",
    "    dict_param['w2'] = np.sign(np.load(data_dir+\"w2.npy\")).T\n",
    "    dict_param['size_output'],_ = np.shape(dict_param['w2'])\n",
    "\n",
    "    # MNIST dataset\n",
    "    test_dataset = torchvision.datasets.MNIST(root='data',\n",
    "                                              train=False,\n",
    "                                              transform=transforms.ToTensor())\n",
    "    return dict_param, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     8
    ]
   },
   "outputs": [],
   "source": [
    "def set_param(dict_param, test_dataset, restriction=False,  flip_rate=0.5):\n",
    "    x, label = choice(test_dataset)\n",
    "    x = x.reshape(28*28).numpy()*2-1\n",
    "    x = np.sign(x)\n",
    "    x[x==0] = 1 \n",
    "    w0,w1,w2 = (dict_param[name] for name in ['w0','w1','w2'])\n",
    "    confidence_vec = w2@np.sign(dict_param['w1']@np.sign(dict_param['w0']@x))\n",
    "    label_predicted = np.argmax(confidence_vec)\n",
    "    if restriction is True:\n",
    "        flips = 2*np.random.binomial(n=1, p=1-flip_rate, size=dict_param['size_input'])-1\n",
    "        x_turb = x * flips\n",
    "        target = np.argmax(w2@np.sign(dict_param['w1']@np.sign(dict_param['w0']@x_turb)))\n",
    "        dict_param['set_const'] = np.nonzero(flips==1)[0]\n",
    "        dict_param['set_var'] = np.nonzero(flips != 1)[0]\n",
    "        print('the number of flips is {}'.format(len(dict_param['set_var'])))\n",
    "    else:\n",
    "        dict_param['set_var'] = range(dict_param['size_input'])\n",
    "        dict_param['set_const'] = range(0)\n",
    "        select_range = np.nonzero(confidence_vec<np.max(confidence_vec))[0] # avoid equal confidence level\n",
    "        #target = (label_predicted + np.random.randint(9) + 1) % 10\n",
    "        if len(select_range) == 0:\n",
    "            raise Exception('Weird! All confidence levels are same!')\n",
    "        target = select_range[np.random.randint(len(select_range))]\n",
    "    print(label, label_predicted, target)\n",
    "    dict_param['target'] = target\n",
    "    dict_param['label_original'] = label\n",
    "    dict_param['label_predicted'] = label_predicted\n",
    "    dict_param['x'] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build MIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     50,
     124,
     139,
     184,
     196,
     259
    ]
   },
   "outputs": [],
   "source": [
    "class MinistExtendedFormulation(object):\n",
    "    def __init__(self, dict_param, is_conv=False, is_integral=False,\n",
    "                 is_branchPriority=False, obj_type=GRB.MINIMIZE, pixel_change_tol=784, model_attrs={}):\n",
    "        self.model = gp.Model(\"robustness_BNN\")\n",
    "        self.param = dict_param\n",
    "        self.is_conv = is_conv\n",
    "        self.is_integral= is_integral\n",
    "        self.is_branchPriority = is_branchPriority\n",
    "        self.obj_type = obj_type\n",
    "        self.pixel_change_tol = pixel_change_tol\n",
    "        self.model_attrs = model_attrs\n",
    "        \n",
    "        self.vars = {}\n",
    "        self.vars_incumbent = dict(Status=False)\n",
    "        self.confidence_level = 0.\n",
    "        self.result_only = True # save the result only\n",
    "    \n",
    "    def setup(self):\n",
    "        \"\"\"set up the corresponding model\n",
    "        \"\"\"\n",
    "        self.model.setParam(\"TimeLimit\", 1800)        \n",
    "        self.model.setParam(\"PreCrush\", 1)\n",
    "        #if self.is_integral is False:\n",
    "            #choose barrier method for continuous models\n",
    "            #self.model.setParam(\"Method\", 2)\n",
    "            #Disable crossover to accelarate the algorithm\n",
    "            #self.model.setParam(\"Crossover\", 0)\n",
    "            \n",
    "        for key,value in self.model_attrs.items():\n",
    "            self.model.setParam(key, value)\n",
    "            \n",
    "        model = self.model\n",
    "        w0,w1,w2= (self.param[name] for name in ['w0','w1','w2'])\n",
    "        x = self.param['x']\n",
    "        \n",
    "        model._param = self.param\n",
    "        model._num_usercut = 0\n",
    "        \n",
    "        size_input = self.param['size_input']\n",
    "        size_hidden = self.param['size_hidden']\n",
    "        size_output = self.param['size_output']\n",
    "        \n",
    "        label_predicted = dict_param['label_predicted']\n",
    "        target = self.param['target']\n",
    "        \n",
    "        type_var = GRB.BINARY if self.is_integral else GRB.CONTINUOUS\n",
    "        \n",
    "        x0 = model.addVars(range(size_input), vtype=type_var, ub=1., name='x0')        \n",
    "        x1 = model.addVars(range(size_hidden[0]), vtype=type_var, ub=1., name='x1')\n",
    "        x2 = model.addVars(range(size_hidden[1]), vtype=type_var, ub=1., name='x2')     \n",
    "        if self.is_branchPriority is True:\n",
    "            # branch on lower-lever variables first\n",
    "            priority = 1\n",
    "            for i in x2:\n",
    "                x2[i].branchPriority = priority\n",
    "            priority = priority + 1\n",
    "            for i in x1:\n",
    "                x1[i].branchPriority = priority\n",
    "            priority = priority + 1\n",
    "            for i in x0:\n",
    "                x0[i].branchPriority = priority\n",
    "        \n",
    "        y0 = model.addVars(range(size_input), lb=-1., ub=1., vtype=GRB.CONTINUOUS, name='y0')\n",
    "        y1 = model.addVars(range(size_hidden[0]), lb=-1., ub=1., vtype=GRB.CONTINUOUS, name='y1')\n",
    "        y2 = model.addVars(range(size_hidden[1]), lb=-1., ub=1., vtype=GRB.CONTINUOUS, name='y2')\n",
    "        \n",
    "        self.vars['y0'] = y0\n",
    "        self.vars['y1'] = y1\n",
    "        self.vars['y2'] = y2\n",
    "        model._vars = self.vars\n",
    "        #self.vars['z0'] = z0\n",
    "        \n",
    "        model.addConstrs(y0[j] <= 2*x0[j] - 1. for j in range(size_input))\n",
    "        model.addConstrs(y1[j] <= 2*x1[j] - 1. for j in range(size_hidden[0]))\n",
    "        model.addConstrs(y2[j] <= 2*x2[j] - 1. for j in range(size_hidden[1]))\n",
    "        \n",
    "        model.addConstrs(y0[j] >= 2*x0[j] - 1. for j in range(size_input))\n",
    "        model.addConstrs(y1[j] >= 2*x1[j] - 1. for j in range(size_hidden[0]))\n",
    "        model.addConstrs(y2[j] >= 2*x2[j] - 1. for j in range(size_hidden[1]))\n",
    "        \n",
    "        if self.is_conv is True:\n",
    "            self.add_constrs_conv()\n",
    "        else:\n",
    "            self.add_constrs_natural()\n",
    "            \n",
    "        if self.obj_type == GRB.MINIMIZE:\n",
    "            model.addConstrs(gp.quicksum(w2[j, k]*y2[k] for k in range(size_hidden[1])) <= \n",
    "                          gp.quicksum(w2[target, k]*y2[k] for k in range(size_hidden[1])) for j in range(size_output) if j != target)\n",
    "            model.setObjective(size_input/2-gp.quicksum(x[j]*y0[j]/2 for j in range(size_input)), GRB.MINIMIZE)\n",
    "        elif self.obj_type == GRB.MAXIMIZE:\n",
    "            model.addConstr(size_input-gp.quicksum(x[j]*y0[j] for j in range(size_input)) <= 2*self.pixel_change_tol)\n",
    "            model.setObjective(gp.quicksum(w2[target, k]*y2[k] for k in range(size_hidden[1])) - \n",
    "                               gp.quicksum(w2[label_predicted, k]*y2[k] for k in range(size_hidden[1])), GRB.MAXIMIZE)\n",
    "    \n",
    "    def set_confidence_level(self, confidence_level):\n",
    "        self.confidence_level = confidence_level\n",
    "        self.model = gp.Model(\"robustness_BNN\")\n",
    "        self.vars_incumbent = dict(Status=False)\n",
    "        \n",
    "    def add_constrs_natural(self):\n",
    "        model = self.model\n",
    "        size_hidden = self.param['size_hidden'] \n",
    "        size_input = self.param['size_input'] \n",
    "        w0,w1 = (self.param[name] for name in ['w0','w1'])\n",
    "        y0,y1,y2= (self.vars[name] for name in ['y0','y1','y2'])\n",
    "        # for each hidden layer, denote t as the output vector, y as the input vector and (row, col) as the shape of the weight matrix\n",
    "#         for t,y,weights,row,col in zip((y1, y2), (y0, y1), (w0, w1), size_hidden, (size_input, size_hidden[0])):\n",
    "#             #print(w)\n",
    "#             #pdb.set_trace()\n",
    "#             name = name='h'+str(col)+'L'\n",
    "#             model.addConstrs((gp.quicksum(weights[i,j]*y[j] for j in range(col)) + col >= col * t[i] for i in range(row)), name=name)\n",
    "#             name='h'+str(col)+'U'\n",
    "#             model.addConstrs((gp.quicksum(weights[i,j]*y[j] for j in range(col)) - col + 1. <= col * y1[i] for i in range(row)), name=name)\n",
    "            \n",
    "        model.addConstrs(gp.quicksum(w0[i,j]*y0[j] for j in range(size_input)) + size_input\n",
    "                         >= size_input * y1[i] for i in range(size_hidden[0]))\n",
    "        model.addConstrs(gp.quicksum(w0[i,j]*y0[j] for j in range(size_input)) - size_input + 1.\n",
    "                         <= size_input * y1[i] for i in range(size_hidden[0]))\n",
    "        \n",
    "        model.addConstrs(gp.quicksum(w1[i,j]*y1[j] for j in range(size_hidden[0])) + size_hidden[0]\n",
    "                         >= size_hidden[0] * y2[i] for i in range(size_hidden[1]))\n",
    "        model.addConstrs(gp.quicksum(w1[i,j]*y1[j] for j in range(size_hidden[0])) - size_hidden[0] + 1.\n",
    "                         <= size_hidden[1] * y2[i] for i in range(size_hidden[1]))\n",
    "        \n",
    "    def add_constrs_conv(self):\n",
    "        model = self.model\n",
    "        size_hidden = self.param['size_hidden'] \n",
    "        size_input = self.param['size_input'] \n",
    "        w0,w1 = (self.param[name] for name in ['w0','w1'])\n",
    "        y0,y1,y2= (self.vars[name] for name in ['y0','y1','y2'])\n",
    "        # for each hidden layer, denote t as the output vector, y as the input vector and (row, col) as the shape of the weight matrix\n",
    "        for t,y,w,row,col in zip((y1, y2), (y0, y1), (w0, w1), size_hidden, (size_input, size_hidden[0])):\n",
    "            z_aux = model.addVars(range(row), range(col), lb=-1.0, vtype=GRB.CONTINUOUS)\n",
    "            model.addConstrs(-(1.+t[i])<=2*z_aux[i,j] for i in range(row) for j in range(col))\n",
    "            model.addConstrs(2*z_aux[i,j]<=(1.+t[i]) for i in range(row) for j in range(col))\n",
    "            model.addConstrs(-(1-t[i])<=2*(w[i,j]*y[j]-z_aux[i,j]) for i in range(row) for j in range(col))\n",
    "            model.addConstrs(2*(w[i,j]*y[j]-z_aux[i,j])<=(1-t[i]) for i in range(row) for j in range(col))\n",
    "            model.addConstrs(z_aux.sum(i, '*')>=0 for i in range(row))\n",
    "            model.addConstrs(gp.quicksum(w[i,j]*y[j] for j in range(col))-z_aux.sum(i,'*')<=(t[i]-1) for i in range(row))\n",
    "    def __repr__(self):\n",
    "        status = self.vars_incumbent['Status']\n",
    "        s = ''\n",
    "        if status is False:\n",
    "            s = s + 'The optimization problem has not been solved. Please try to solve the problem first.'\n",
    "        elif status != GRB.OPTIMAL:\n",
    "            s = s + 'The solver is not able to solve the problem to optimality.'\n",
    "        else:\n",
    "            s = s + ('The solver is able to solve the problem to optimality within {}.\\n'.format(self.vars_incumbent['time']))\n",
    "            s = s + ('The original input is:\\n{}\\n'.format(self.param['x']))\n",
    "            y0,y1,y2 = (self.vars_incumbent[name] for name in ['y0', 'y1', 'y2'])\n",
    "            s= s + ('The targeted input is:\\n{}\\n'.format(y0))\n",
    "            s= s + ('The hidden layers are:\\n{},\\n\\n{},\\n\\n{}\\n'.format(y1, y2))\n",
    "        return s\n",
    "\n",
    "    def __call__(self, callback=None):\n",
    "        if self.vars_incumbent['Status'] is False:\n",
    "            self.setup()          \n",
    "            \n",
    "        if callback is None:\n",
    "            self.model.optimize()\n",
    "        elif self.is_integral is False:\n",
    "            self.model.setParam(\"OutputFlag\", 0)\n",
    "            self.model._tol = self.model.Params.FeasibilityTol\n",
    "            #self.model._tol = 1e-5\n",
    "            self.model._iter_tol = 10000\n",
    "            self.model._iter = 0\n",
    "            #self.model._lazy_status = False\n",
    "            obj_previous = -1e5\n",
    "            obj_current = 1e5\n",
    "            while np.abs(obj_previous-obj_current)>self.model._tol*self.model._tol:\n",
    "            #while (self.model._lazy_status is False) and (np.abs(obj_previous-obj_current)<=self.model._tol):\n",
    "                self.model.optimize()\n",
    "                obj_previous = obj_current\n",
    "                obj_current = self.model.objVal\n",
    "                callback(self.model)\n",
    "        else:\n",
    "            self.model._tol = 0\n",
    "            self.model.optimize(callback)\n",
    "            #self.model.optimize(conv_cb)\n",
    "        self.vars_incumbent['Status'] = self.model.getAttr('Status')\n",
    "        if self.vars_incumbent['Status'] == GRB.OPTIMAL:\n",
    "            print('The objective is {}'.format(self.model.objVal))\n",
    "            self.set_optimal_sols()\n",
    "        \n",
    "    def set_optimal_sols(self, is_print=True):\n",
    "        model = self.model\n",
    "        size_input = self.param['size_input']\n",
    "        size_hidden = self.param['size_hidden'] \n",
    "        names_vars = ['y0','y1','y2']\n",
    "        y0,y1,y2= (self.vars[name] for name in names_vars)\n",
    "        self.vars_incumbent['y0'] = np.array(model.getAttr(\"X\", y0).values())\n",
    "        self.vars_incumbent['y1'] = np.array(model.getAttr(\"X\", y1).values())\n",
    "        self.vars_incumbent['y2'] = np.array(model.getAttr(\"X\", y2).values())\n",
    "        self.vars_incumbent['objVal'] = model.objVal\n",
    "        self.vars_incumbent['time'] = model.getAttr('Runtime')\n",
    "    \n",
    "    def save(self, filename, result_only=True):\n",
    "#         if self.vars_incumbent['Status'] == GRB.OPTIMAL:\n",
    "#             model = self.model\n",
    "#             x = self.param['x']\n",
    "#             target = self.param['target']\n",
    "#             names_incumbent = ['y0','y1','y2', 'objVal','time', 'Status']\n",
    "#             y0,y1,y2,y3,objVal,time,status = (self.vars_incumbent[name] for name in names_incumbent)\n",
    "#             dict_instance = {'x':x, 'y0':y0, 'y1':y1, 'y2':y2, \n",
    "#                          'target':target, 'time':time, 'Status':status,  'objVal':objVal}\n",
    "#             # model\n",
    "#             model.write(filename+'.mps')\n",
    "#             # MIP start\n",
    "#             model.write(filename+'.mst')\n",
    "#             # save solutinos\n",
    "#             model.write(filename+'.json')\n",
    "#             # save parameters\n",
    "#             with open(filename, 'wb') as f:\n",
    "#                 pickle.dump(dict_instance, f)\n",
    "            \n",
    "#         else:\n",
    "#             raise Exception('The status is not OPTIMAL!')\n",
    "        \n",
    "        x = self.param['x']\n",
    "        target = self.param['target']\n",
    "        label_original = self.param['label_original']\n",
    "        label_predicted = self.param['label_predicted']\n",
    "        names_incumbent = ['y0','y1','y2', 'objVal','time', 'Status']\n",
    "        dict_instance = {'confidence_level':self.confidence_level, 'label_original':label_original,\n",
    "                     'label_predicted':label_predicted, 'target':target, 'time':self.model.getAttr('Runtime')}\n",
    "        \n",
    "        try:\n",
    "            names_incumbent = ['y0','y1','y2', 'objVal','time', 'Status']\n",
    "            y0,y1,y2,objVal,time,status = (self.vars_incumbent[name] for name in names_incumbent)\n",
    "            dict_instance.update({'x':x, 'y0':y0, 'y1':y1, 'y2':y2, \n",
    "                         'time':time, 'Status':status,  'objVal':objVal})\n",
    "            model = self.model\n",
    "        except:\n",
    "            dict_instance['Status'] = -1\n",
    "            \n",
    "        if self.is_integral is True:\n",
    "            try:\n",
    "                dict_instance['gap'] = self.model.getAttr('MIPGap')\n",
    "                dict_instance['bound'] = self.model.getAttr('ObjBound')\n",
    "                dict_instance['objVal'] = self.model.getAttr('objVal')\n",
    "                dict_instance['time'] = self.model.getAttr('Runtime')\n",
    "                dict_instance['Status'] = self.model.getAttr('Status')\n",
    "            except:\n",
    "                print('MIP failed to save!')\n",
    "                dict_instance = {'Status':-1}\n",
    "\n",
    "        self.result_only = result_only\n",
    "        if result_only is False:\n",
    "            # model\n",
    "            model.write(filename+'.mps')\n",
    "            # MIP start\n",
    "            model.write(filename+'.mst')\n",
    "            # save solutinos\n",
    "            model.write(filename+'.json')\n",
    "            \n",
    "            # save parameters\n",
    "        with open(filename, 'wb') as f:\n",
    "                pickle.dump(dict_instance, f)\n",
    "            \n",
    "    def load(self, filename):\n",
    "        self.model = gp.read(filename+'.mps')\n",
    "        size_input = self.param['size_input']\n",
    "        size_hidden = self.param['size_hidden'] \n",
    "        with open(filename, 'rb') as f:\n",
    "            dict_instance = pickle.load(f)\n",
    "        self.param['x'] = dict_instance['x']\n",
    "        self.param['target'] = dict_instance['target']\n",
    "        names_incumbent = ['y0','y1','y2','objVal','time', 'Status']\n",
    "        for name in names_incumbent:\n",
    "            self.vars_incumbent[name] = dict_instance[name]\n",
    "        self.model.read(filename+'.mst')\n",
    "        self.vars['y0'] = dict(zip(range(size_input), ((x for x in instance2.model.getVars() if x.VarName.find('y0') != -1))))\n",
    "        self.vars['y1'] = dict(zip(range(size_hidden[0]), ((x for x in instance2.model.getVars() if x.VarName.find('y1') != -1))))\n",
    "        self.vars['y2'] = dict(zip(range(size_hidden[1]), ((x for x in instance2.model.getVars() if x.VarName.find('y2') != -1))))\n",
    "        self.model.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def conv_cb(model, where):\n",
    "    if where == GRB.Callback.MIPNODE:\n",
    "        status = model.cbGet(GRB.Callback.MIPNODE_STATUS)\n",
    "        #if (status == GRB.OPTIMAL):\n",
    "        #if (status == GRB.OPTIMAL) and (model.cbGet(GRB.Callback.MIPNODE_NODCNT)<= 100):\n",
    "        # only adding cutting planes at the root node\n",
    "        if (status == GRB.OPTIMAL) and (model.cbGet(GRB.Callback.MIPNODE_NODCNT)==0):\n",
    "            #pdb.set_trace()        \n",
    "            size_hidden = model._param['size_hidden'] # number of constraints            \n",
    "            size_input = model._param['size_input'] # number of variables\n",
    "            w0,w1 = (model._param[name] for name in ['w0','w1'])\n",
    "            y0,y1,y2= (model._vars[name] for name in ['y0','y1','y2'])\n",
    "            for weights,y,y_out,m,n in zip((w0,w1), (y0,y1), (y1,y2), size_hidden, (size_input, size_hidden[0])):\n",
    "                #pdb.set_trace()\n",
    "                y_incumbent = np.array(model.cbGetNodeRel(y).select())\n",
    "                y_out_incumbent = np.array(model.cbGetNodeRel(y_out).select())\n",
    "                for i in range(m):\n",
    "                    w = weights[i,:]\n",
    "                    t = y_out_incumbent[i]\n",
    "                    if np.sum(np.minimum(w*y_incumbent, t)) < n/2*(t-1) - model._tol:\n",
    "                        indices = np.where(w*y_incumbent<t)[0]\n",
    "                        # (|J|-n/2)t-n/2 <= \\sum_{j\\in J} w_j*y_j\n",
    "                        model.cbCut((len(indices)-n/2)*y_out[i] - n/2 <= gp.quicksum(weights[i,j]*y[j] for j in indices))\n",
    "                        model._num_usercut = model._num_usercut + 1\n",
    "\n",
    "                    if np.sum(np.maximum(w*y_incumbent, t)) > (n+2)*(t+1)/2-2+model._tol:\n",
    "                        indices = np.where(w*y_incumbent>t)[0]\n",
    "                        # (|J|+1-n/2)t+n/2-1 >= \\sum_{j\\in J} w_j*y_j\n",
    "                        #pdb.set_trace()\n",
    "                        model.cbCut((len(indices)-n/2+1)*y_out[i]+n/2-1 >= gp.quicksum(weights[i,j]*y[j] for j in indices))\n",
    "                        model._num_usercut = model._num_usercut + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cut(model):  \n",
    "    size_hidden = model._param['size_hidden'] # number of constraints            \n",
    "    size_input = model._param['size_input'] # number of variables\n",
    "    w0,w1 = (model._param[name] for name in ['w0','w1'])\n",
    "    y0,y1,y2= (model._vars[name] for name in ['y0','y1','y2'])\n",
    "    model._iter = model._iter + 1\n",
    "    for weights,y,y_out,m,n in zip((w0,w1), (y0,y1), (y1,y2), size_hidden, (size_input, size_hidden[0])):\n",
    "        #pdb.set_trace()\n",
    "        y_incumbent = np.array(model.getAttr(\"X\", y).values())\n",
    "        y_out_incumbent = np.array(model.getAttr(\"X\", y_out).values())\n",
    "        for i in range(m):\n",
    "            w = weights[i,:]\n",
    "            t = y_out_incumbent[i]\n",
    "            if np.sum(np.minimum(w*y_incumbent, t)) < n/2*(t-1) - model._tol:\n",
    "                indices = np.where(w*y_incumbent<t)[0]\n",
    "                # (|J|-n/2)t-n/2 <= \\sum_{j\\in J} w_j*y_j\n",
    "                model.addConstr((len(indices)-n/2)*y_out[i] - n/2 <= gp.quicksum(weights[i,j]*y[j] for j in indices))\n",
    "                model._num_usercut = model._num_usercut + 1\n",
    "                #model._lazy_status = False\n",
    "\n",
    "            if np.sum(np.maximum(w*y_incumbent, t)) > (n+2)*(t+1)/2-2+model._tol:\n",
    "                indices = np.where(w*y_incumbent>t)[0]\n",
    "                # (|J|+1-n/2)t+n/2-1 >= \\sum_{j\\in J} w_j*y_j\n",
    "                #pdb.set_trace()\n",
    "                model.addConstr((len(indices)-n/2+1)*y_out[i]+n/2-1 >= gp.quicksum(weights[i,j]*y[j] for j in indices))\n",
    "                model._num_usercut = model._num_usercut + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with varying changing tolerance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_conv = {}\n",
    "obj_natural = {}\n",
    "obj_conv_int = {}\n",
    "obj_natural_int = {}\n",
    "\n",
    "root_dir = 'experiment_results/robustness_integral_size_hidden2_max_with_varying_pixel_tol/'\n",
    "for size_hidden in [256,]:\n",
    "    data_dir = '2_layer_weights/' + str(size_hidden) + '/'\n",
    "    dict_param, test_dataset = load_data(data_dir=data_dir)\n",
    "    for idx_instance in [1,3,4]:\n",
    "        set_param(dict_param, test_dataset)\n",
    "        pixel_change_range = [0,1,2,3,4,5] # allowed to change about 5% of pixels\n",
    "        print('Hidden size:{}, instance index:{}'.format(size_hidden, idx_instance+1)+'*'*40+'{}'.format(datetime.datetime.now()))\n",
    "        for pixel_change_tol in pixel_change_range:\n",
    "            print('Hidden size:{}, instance index:{}, tolerance:{}'.format(size_hidden, idx_instance+1, pixel_change_range)\n",
    "                  +'*'*40+'{}'.format(datetime.datetime.now()))\n",
    "            instance_natural = MinistExtendedFormulation(dict_param, is_integral=False,\n",
    "                                                         obj_type=GRB.MAXIMIZE, pixel_change_tol=pixel_change_tol)\n",
    "            print('\\n NATURAL RELAXATION STARTS TO SOLVE'+'-'*20\n",
    "                  +'# hidden neurons'+str(size_hidden)+','+'#instance'+str(idx_instance+1)+',tol'+str(pixel_change_tol)+'\\n')\n",
    "            instance_natural()\n",
    "            try:\n",
    "                instance_natural.save(root_dir+'nat{}_{}_{}'.format(int(size_hidden), int(idx_instance), int(pixel_change_tol)))                              \n",
    "                obj_natural[str(size_hidden), str(idx_instance), str(pixel_change_tol)] = instance_natural.vars_incumbent['objVal']\n",
    "            except KeyError:\n",
    "                print('Oops! The model is not optimal!')\n",
    "                obj_natural[str(size_hidden), str(idx_instance)] = -1           \n",
    "\n",
    "\n",
    "            instance_conv = MinistExtendedFormulation(dict_param, is_integral=False,\n",
    "                                                      obj_type=GRB.MAXIMIZE, pixel_change_tol=pixel_change_tol)\n",
    "            print('\\n STRONG RELAXATION STARTS TO SOLVE!'+'-'*20\n",
    "                  +'# hidden neurons'+str(size_hidden)+','+'#instance'+str(idx_instance+1)+',tol'+str(pixel_change_tol)+'\\n')\n",
    "            instance_conv(add_cut)\n",
    "            try:\n",
    "                instance_conv.save(root_dir+'conv{}_{}_{}'.format(int(size_hidden), int(idx_instance), int(pixel_change_tol)))\n",
    "                obj_conv[str(size_hidden), str(idx_instance), str(pixel_change_tol)] = instance_conv.vars_incumbent['objVal']\n",
    "            except KeyError:\n",
    "                print('Oops! The model is not optimal!')\n",
    "                obj_conv[str(size_hidden), str(idx_instance)] = -1\n",
    "\n",
    "            instance_natural_int = MinistExtendedFormulation(dict_param, is_integral=True,\n",
    "                                                             obj_type=GRB.MAXIMIZE, pixel_change_tol=pixel_change_tol)\n",
    "            print('\\n NATURAL MIP STARTS TO SOLVE!'+'-'*20\n",
    "                  +'# hidden neurons'+str(size_hidden)+','+'#instance'+str(idx_instance+1)+',tol'+str(pixel_change_tol)+'\\n')\n",
    "            instance_natural_int()\n",
    "            try:\n",
    "                instance_natural_int.save(root_dir+'nat_int{}_{}_{}'.format(int(size_hidden), int(idx_instance), int(pixel_change_tol)))                              \n",
    "                obj_natural_int[str(size_hidden), str(idx_instance), str(pixel_change_tol)] = instance_natural_int.vars_incumbent['objVal']\n",
    "            except KeyError:\n",
    "                print('Oops! The model is not optimal!')\n",
    "                obj_natural_int[str(size_hidden), str(idx_instance)] = -1\n",
    "\n",
    "            instance_conv_int = MinistExtendedFormulation(dict_param, is_integral=True,\n",
    "                                                          obj_type=GRB.MAXIMIZE, pixel_change_tol=pixel_change_tol)\n",
    "            print('\\n STRONG MIP STARTS TO SOLVE!'+'-'*20\n",
    "                  +'# hidden neurons'+str(size_hidden)+','+'#instance'+str(idx_instance+1)+',tol'+str(pixel_change_tol)+'\\n')\n",
    "            instance_conv_int(conv_cb)\n",
    "            try:\n",
    "                instance_conv_int.save(root_dir+'conv_int{}_{}_{}'.format(int(size_hidden), int(idx_instance), int(pixel_change_tol)))                              \n",
    "                obj_conv_int[str(size_hidden), str(idx_instance), str(pixel_change_tol)] = instance_conv_int.vars_incumbent['objVal']\n",
    "            except KeyError:\n",
    "                print('Oops! The model is not optimal!')\n",
    "                obj_conv_int[str(size_hidden), str(idx_instance)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_decimal(x):    \n",
    "    if x==np.inf:\n",
    "        s = '-'\n",
    "    else:\n",
    "        s = '{:.2f}'.format(x)\n",
    "    return s\n",
    "def format_int(x):\n",
    "    if x==np.inf:\n",
    "        s = '-'\n",
    "    else:\n",
    "        s = '{:d}'.format(int(x))\n",
    "    return s\n",
    "experiment_frame = pd.DataFrame({'dim_hidden':[], 'pixel_change_tol':[], 'label':[],\n",
    "                                 'nat_relax':[], 'nat_obj':[], 'nat_bound':[], 'nat_gap':[], 'nat_time':[],\n",
    "                                 'conv_relax':[], 'conv_obj':[], 'conv_bound':[], 'conv_gap':[], 'conv_time':[], 'rimp':[]})\n",
    "root_dir = 'experiment_results/robustness_integral_size_hidden2_max_with_varying_pixel_tol/'\n",
    "n=0\n",
    "for size_hidden in [32, 64, 128, 256,]:\n",
    "    dim_hidden = size_hidden\n",
    "    pixel_change_range = [1,2,3,4,5]\n",
    "    for pixel_change_tol in pixel_change_range:\n",
    "        for idx_instance in range(5):\n",
    "            filename = root_dir + 'nat{}_{}_{}'.format(int(size_hidden), int(idx_instance), int(pixel_change_tol))\n",
    "            with open(filename, 'rb') as f:\n",
    "                d = pickle.load(f)\n",
    "            label = (d['label_original'], d['label_predicted'], d['target'])\n",
    "            nat_relax = d['objVal']\n",
    "\n",
    "            filename = root_dir + 'conv{}_{}_{}'.format(int(size_hidden), int(idx_instance), int(pixel_change_tol))\n",
    "            with open(filename, 'rb') as f:\n",
    "                d = pickle.load(f)\n",
    "                \n",
    "            try:\n",
    "                conv_relax = d['objVal']\n",
    "            except:\n",
    "                conv_relax = np.nan\n",
    "#             if d['Status'] != -1:\n",
    "#                 conv_relax = d['objVal']\n",
    "#             else:\n",
    "#                 conv_relax = np.nan\n",
    "\n",
    "            filename = root_dir + 'nat_int{}_{}_{}'.format(int(size_hidden), int(idx_instance), int(pixel_change_tol))\n",
    "            with open(filename, 'rb') as f:\n",
    "                d = pickle.load(f)\n",
    "            nat_obj = d['objVal']\n",
    "            nat_bound = d['bound']\n",
    "            nat_gap = d['gap']*100\n",
    "            nat_time = d['time']\n",
    "\n",
    "            filename = root_dir + 'conv_int{}_{}_{}'.format(int(size_hidden), int(idx_instance), int(pixel_change_tol))\n",
    "            with open(filename, 'rb') as f:\n",
    "                d = pickle.load(f)\n",
    "            conv_obj = d['objVal']\n",
    "            conv_bound = d['bound']\n",
    "            conv_gap = d['gap']*100\n",
    "            conv_time = d['time']\n",
    "            rimp = 100*(nat_relax-conv_relax)/(nat_relax-nat_obj + (np.abs(nat_relax-nat_obj)<=1e-4))\n",
    "\n",
    "            list_frame = ['','', label,  nat_relax,  nat_obj, nat_bound, nat_gap, nat_time,\n",
    "                                       conv_relax, conv_obj, conv_bound, conv_gap, conv_time, rimp]\n",
    "            if idx_instance == 0:\n",
    "                list_frame[0] = dim_hidden\n",
    "                list_frame[1] = pixel_change_tol\n",
    "\n",
    "            experiment_frame.loc[n] = list_frame\n",
    "            n= n + 1\n",
    "        list_frame = ['', '', 'Ave'] + list(experiment_frame[-5:].mean())\n",
    "        experiment_frame.loc[n] = list_frame\n",
    "        n = n + 1\n",
    "    \n",
    "        \n",
    "formatters = [None,  None, None,format_decimal, format_int, format_int, format_int, format_decimal, format_decimal,\n",
    "              format_int, format_int, format_int, format_decimal, format_decimal]        \n",
    "latex_str = experiment_frame.to_latex(index=False, formatters=formatters)\n",
    "print(latex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_frame.to_csv(root_dir+'results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
